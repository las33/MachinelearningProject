{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import itertools\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "from pyfpgrowth import find_frequent_patterns as fpgrowth\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 0\n",
    "input_file = \"contextPasquier99.txt\"\n",
    "output_file = open('outfile', 'w')\n",
    "n_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db_as_list(filename):\n",
    "    global support\n",
    "    transactions = []\n",
    "    n_transactions = 0\n",
    "    with open(filename) as finput:\n",
    "        f = finput.read().split('\\n')\n",
    "        transactions = list(map(lambda x: x.strip().split(' '), f))\n",
    "        finput.close()\n",
    "    transactions = list(filter(lambda x: x!=[''], transactions))\n",
    "        \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_itemset_1(filename, minsup):\n",
    "    global support\n",
    "    itemset_1 = {}\n",
    "    n_transactions = 0\n",
    "    with open(filename) as finput:\n",
    "        f = finput.read().split('\\n')\n",
    "        for line in f:\n",
    "            n_transactions += 1\n",
    "            items = line.strip().split(' ')\n",
    "            for item in items:\n",
    "                if item not in itemset_1:\n",
    "                    itemset_1[item] = 0\n",
    "                itemset_1[item] += 1\n",
    "    support = n_transactions * minsup\n",
    "    \n",
    "    for k, v in list(itemset_1.items()):\n",
    "        if v < support:\n",
    "            del itemset_1[k]\n",
    "    return itemset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPCNode:\n",
    "    def __init__(self):\n",
    "        self.pre_order = None\n",
    "        self.post_order = None\n",
    "        self.count = None\n",
    "        self.label = None\n",
    "        self.parent = None\n",
    "        self.child = None\n",
    "        self.sibling = None\n",
    "\n",
    "\n",
    "class FPTNode:\n",
    "    def __init__(self):\n",
    "        self.equivalent_items = None\n",
    "        self.child_nodes = None\n",
    "        self.label = None\n",
    "        self.itemset = None\n",
    "        self.support = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(root, label):\n",
    "    node = PPCNode()\n",
    "    node.label = label\n",
    "    node.count = 1\n",
    "    node.parent = root\n",
    "    return node\n",
    "\n",
    "\n",
    "def insert_ppc_node(root, item):\n",
    "    if root.child is None:\n",
    "        node = create_node(root, item)\n",
    "        root.child = node\n",
    "        return root.child\n",
    "    elif root.child.label == item:\n",
    "        root.child.count += 1\n",
    "        return root.child\n",
    "    elif root.child.sibling is None:\n",
    "        node = create_node(root, item)\n",
    "        root.child.sibling = node\n",
    "        return root.child.sibling\n",
    "    else:\n",
    "        current_sibling = root.child.sibling\n",
    "        last_sibling = None\n",
    "        while current_sibling is not None:\n",
    "            if current_sibling.label == item:\n",
    "                current_sibling.count += 1\n",
    "                return current_sibling\n",
    "            else:\n",
    "                last_sibling = current_sibling\n",
    "                current_sibling = current_sibling.sibling\n",
    "        node = create_node(root, item)\n",
    "        last_sibling.sibling = node        \n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_post(root, pre=0, post=0):\n",
    "    root.pre_order = pre\n",
    "    post_ = post\n",
    "    if root.child is not None:\n",
    "        root.child.pre_order = pre + 1\n",
    "        pre, post_ = pre_post(root.child, root.child.pre_order, post)\n",
    "    root.post_order = post_\n",
    "    if root.sibling is not None:\n",
    "        root.sibling.pre_order = pre + 1\n",
    "        pre, post_ = pre_post(root.sibling, root.sibling.pre_order, root.post_order + 1)\n",
    "        return pre, post_\n",
    "    return pre, post_ + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ppc_tree(filename, itemset_1):\n",
    "    root = PPCNode()\n",
    "    with open(filename) as finput:\n",
    "        f = finput.read().split('\\n')\n",
    "        for line in f:\n",
    "            items = line.strip().split(' ')            \n",
    "            transaction = []\n",
    "            for item in items:\n",
    "                if item in list(itemset_1.keys()):\n",
    "                    transaction.append((item, itemset_1[item]))\n",
    "            transaction.sort(key=lambda x: x[0])\n",
    "            transaction.sort(key=lambda x: x[1], reverse=True)\n",
    "            root_aux = root\n",
    "            for item in transaction:\n",
    "                root_aux = insert_ppc_node(root_aux, item[0])\n",
    "    pre_post(root)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(root):\n",
    "    print(root.label, root.pre_order, root.post_order)\n",
    "    if root.child:\n",
    "        print_tree(root.child)\n",
    "    if root.sibling:\n",
    "        print_tree(root.sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_list(root, n_list={}):\n",
    "    if root.label:\n",
    "        if root.label not in n_list:\n",
    "            n_list[root.label] = []\n",
    "        n_list[root.label].append(((root.pre_order, root.post_order), root.count))\n",
    "    if root.child:\n",
    "        make_n_list(root.child, n_list)\n",
    "    if root.sibling:\n",
    "        make_n_list(root.sibling, n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NL_interserction(n_list1, n_list2, minsup):\n",
    "    n_list_result = []\n",
    "    for k in n_list1:\n",
    "        for l in n_list2:\n",
    "            if k[0][0] < l[0][0] and k[0][1] > l[0][1]:                 \n",
    "                n_list_result.append((k[0], l[1]))\n",
    "    d = {x:0 for x, _ in n_list_result} \n",
    "    for name, num in n_list_result: d[name] += num \n",
    "    n_list_result = list(map(tuple, d.items()))\n",
    "    return n_list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subsets(items, n):\n",
    "    return list(itertools.combinations(items, n))\n",
    "\n",
    "\n",
    "def get_all_subsets(items):\n",
    "    subsets = [find_subsets(items, i) for i in range(len(items)+1)]\n",
    "    subsets = ['-'.join(map(str, item)) for item in list(itertools.chain.from_iterable(subsets))]\n",
    "    return subsets[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_list(key):\n",
    "    global n_list\n",
    "    return n_list[key] if key in n_list else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_pattern_tree(cur_no, next_nos, father_no=None):\n",
    "    global support\n",
    "    global n_list\n",
    "    global output_file\n",
    "    \n",
    "    if cur_no.equivalent_items is None:\n",
    "        cur_no.equivalent_items = []\n",
    "        \n",
    "    cur_no.child_nodes = []\n",
    "    if father_no is not None:\n",
    "        p1 = get_n_list('-'.join([father_no.label, cur_no.label]))\n",
    "    else:\n",
    "        p1 = get_n_list(cur_no.label)\n",
    "        \n",
    "    for i in next_nos:\n",
    "        if father_no is not None:\n",
    "            p2 = get_n_list('-'.join([father_no.label, i.label]))\n",
    "        else:\n",
    "            p2 = get_n_list(i.label)\n",
    "            \n",
    "        p = NL_interserction(p2, p1, support)\n",
    "        p_support = sum([item[1] for item in p])\n",
    "        \n",
    "        if p_support == cur_no.support:\n",
    "            cur_no.equivalent_items += [i.label]\n",
    "        elif p_support >= support:\n",
    "            child = FPTNode()\n",
    "            child.label = i.label\n",
    "            child.support = p_support\n",
    "            cur_no.child_nodes += [child]\n",
    "            if father_no is not None:\n",
    "                n_list['-'.join([father_no.label, cur_no.label, child.label])] = p\n",
    "            else:\n",
    "                n_list['-'.join([cur_no.label, child.label])] = p\n",
    "\n",
    "    if father_no is not None:\n",
    "        cur_no.label = '-'.join([father_no.label, cur_no.label])\n",
    "        \n",
    "    output_file.write(cur_no.label + \" #SUP: \" + str(cur_no.support) + \"\\n\")\n",
    "    \n",
    "    if len(cur_no.equivalent_items) > 0:\n",
    "        subsets = get_all_subsets(cur_no.equivalent_items)\n",
    "        cand_itemsets = [('-'.join([cur_no.label, item]), cur_no.support) for item in subsets]\n",
    "        for itemset in cand_itemsets:\n",
    "            output_file.write(itemset[0] + \" #SUP: \" + str(itemset[1]) + \"\\n\")\n",
    "    \n",
    "    if len(cur_no.child_nodes) > 0:\n",
    "        for child in cur_no.child_nodes:\n",
    "            aheads_ = [i for i in cur_no.child_nodes[cur_no.child_nodes.index(child)+1:]]\n",
    "            child.equivalent_items = list(cur_no.equivalent_items)\n",
    "            building_pattern_tree(child, aheads_, cur_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepostplus(minsup=0):\n",
    "    global support\n",
    "    global output_file\n",
    "    global n_list\n",
    "    \n",
    "    initial_time = time.time()\n",
    "    \n",
    "    itemset_1 = make_itemset_1(input_file, minsup)\n",
    "    tree = build_ppc_tree(input_file, itemset_1)\n",
    "    make_n_list(tree, n_list)\n",
    "\n",
    "    items_ordered = list(itemset_1.items())\n",
    "    items_ordered.sort(key=lambda x: x[0], reverse=True)\n",
    "    items_ordered.sort(key=lambda x: x[1])\n",
    "    items_ordered = [x[0] for x in items_ordered]\n",
    "\n",
    "    nodes = []\n",
    "    for key in list(items_ordered):\n",
    "        node = FPTNode()\n",
    "        node.label = key\n",
    "        node.support = sum([item[1] for item in n_list[key]])\n",
    "        nodes.append(node)\n",
    "\n",
    "    for node in list(nodes):\n",
    "        aheads = nodes[nodes.index(node)+1:]\n",
    "        building_pattern_tree(node, aheads)\n",
    "    final_time = time.time()\n",
    "    \n",
    "    output_file.close()\n",
    "    print(\"Execution time (s):\", final_time - initial_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time (s): 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8daf09f49642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmemory_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepostplus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\barre\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[1;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                 \u001b[0mreturned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# finish timing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-ad9a097efa10>\u001b[0m in \u001b[0;36mprepostplus\u001b[1;34m(minsup)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0maheads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mbuilding_pattern_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maheads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mfinal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e183b74eb869>\u001b[0m in \u001b[0;36mbuilding_pattern_tree\u001b[1;34m(cur_no, next_nos, father_no)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mcur_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfather_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" #SUP: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequivalent_items\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "memory_usage((prepostplus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
