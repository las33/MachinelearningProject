{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from memory_profiler import memory_usage\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support = 2\n",
    "F = []\n",
    "input_file = 'contextPasquier99.txt'\n",
    "output_file = open('outfile_prepostplus_simple', 'w')\n",
    "all_n_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_itemset_1(filename):\n",
    "    global support\n",
    "    itemset_1 = {}\n",
    "    with open(filename) as finput:\n",
    "        f = finput.read().split('\\n')\n",
    "        for line in f:\n",
    "            items = line.strip().split(' ')\n",
    "            for item in items:\n",
    "                if item not in itemset_1:\n",
    "                    itemset_1[item] = 0\n",
    "                itemset_1[item] += 1\n",
    "    \n",
    "    for k, v in list(itemset_1.items()):\n",
    "        if v < support:\n",
    "            del itemset_1[k]\n",
    "    return itemset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PPCNode:\n",
    "    def __init__(self):\n",
    "        self.pre_order = None\n",
    "        self.post_order = None\n",
    "        self.count = None\n",
    "        self.label = None\n",
    "        self.parent = None\n",
    "        self.child = None\n",
    "        self.sibling = None\n",
    "\n",
    "\n",
    "class FPTNode:\n",
    "    def __init__(self):\n",
    "        self.equivalent_items = None\n",
    "        self.child_nodes = None\n",
    "        self.label = None\n",
    "        self.itemset = None\n",
    "        self.support = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_node(root, label):\n",
    "    node = PPCNode()\n",
    "    node.label = label\n",
    "    node.count = 1\n",
    "    node.parent = root\n",
    "    return node\n",
    "\n",
    "\n",
    "def insert_ppc_node(root, item):\n",
    "    if root.child is None:\n",
    "        node = create_node(root, item)\n",
    "        root.child = node\n",
    "        return root.child\n",
    "    elif root.child.label == item:\n",
    "        root.child.count += 1\n",
    "        return root.child\n",
    "    elif root.child.sibling is None:\n",
    "        node = create_node(root, item)\n",
    "        root.child.sibling = node\n",
    "        return root.child.sibling\n",
    "    else:\n",
    "        current_sibling = root.child.sibling\n",
    "        last_sibling = None\n",
    "        while current_sibling is not None:\n",
    "            if current_sibling.label == item:\n",
    "                current_sibling.count += 1\n",
    "                return current_sibling\n",
    "            else:\n",
    "                last_sibling = current_sibling\n",
    "                current_sibling = current_sibling.sibling\n",
    "        node = create_node(root, item)\n",
    "        last_sibling.sibling = node        \n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_post(root, pre=0, post=0):\n",
    "    root.pre_order = pre\n",
    "    post_ = post\n",
    "    if root.child is not None:\n",
    "        root.child.pre_order = pre + 1\n",
    "        pre, post_ = pre_post(root.child, root.child.pre_order, post)\n",
    "    root.post_order = post_\n",
    "    if root.sibling is not None:\n",
    "        root.sibling.pre_order = pre + 1\n",
    "        pre, post_ = pre_post(root.sibling, root.sibling.pre_order, root.post_order + 1)\n",
    "        return pre, post_\n",
    "    return pre, post_ + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ppc_tree(filename, itemset_1):\n",
    "    root = PPCNode()\n",
    "    with open(filename) as finput:\n",
    "        f = finput.read().split('\\n')\n",
    "        for line in f:\n",
    "            items = line.strip().split(' ')            \n",
    "            transaction = []\n",
    "            for item in items:\n",
    "                if item in list(itemset_1.keys()):\n",
    "                    transaction.append((item, itemset_1[item]))\n",
    "                else:\n",
    "                    print('removed:', item)\n",
    "            transaction.sort(key=lambda x: x[1], reverse=True)\n",
    "            root_aux = root\n",
    "            for item in transaction:\n",
    "                root_aux = insert_ppc_node(root_aux, item[0])\n",
    "    pre_post(root)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(root):\n",
    "    print(root.label, root.pre_order, root.post_order)\n",
    "    if root.child:\n",
    "        print_tree(root.child)\n",
    "    if root.sibling:\n",
    "        print_tree(root.sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_n_list(root, n_list={}):\n",
    "    if root.label:\n",
    "        if root.label not in n_list:\n",
    "            n_list[root.label] = []\n",
    "        n_list[root.label].append(((root.pre_order, root.post_order), root.count))\n",
    "    if root.child:\n",
    "        make_n_list(root.child, n_list)\n",
    "    if root.sibling:\n",
    "        make_n_list(root.sibling, n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NL_interserction(n_list1, n_list2, minsup):\n",
    "    n_list_result = []\n",
    "    for k in n_list1:\n",
    "        for l in n_list2:\n",
    "            if k[0][0] < l[0][0] and k[0][1] > l[0][1]:                 \n",
    "                n_list_result.append((k[0], l[1]))\n",
    "    d = {x:0 for x, _ in n_list_result} \n",
    "    for name, num in n_list_result: d[name] += num \n",
    "    n_list_result = list(map(tuple, d.items()))\n",
    "    n_list_result = list(filter(lambda x: x[1] >= minsup, n_list_result))\n",
    "    return n_list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_n2_list(n_list, items_ordered):\n",
    "    global support\n",
    "    global F\n",
    "    n2_list = {}\n",
    "    for i, x in enumerate(items_ordered):\n",
    "        for j in range(i+1, len(items_ordered)):\n",
    "            n_list_result = NL_interserction(n_list[x], n_list[items_ordered[j]], support)\n",
    "            if len(n_list_result) > 0:\n",
    "                key = '-'.join([x, items_ordered[j][0]])\n",
    "                n2_list[key] = n_list_result\n",
    "    return n2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subsets(items, n):\n",
    "    return list(itertools.combinations(items, n))\n",
    "\n",
    "\n",
    "def get_all_subsets(items):\n",
    "    subsets = [find_subsets(items, i) for i in range(len(items)+1)]\n",
    "    subsets = ['-'.join(map(str, item)) for item in list(itertools.chain.from_iterable(subsets))]\n",
    "    return subsets[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_list(key):\n",
    "    global all_n_list\n",
    "    return all_n_list[key] if key in all_n_list else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def building_pattern_tree(node, cad_items, parent_fit):\n",
    "    global support\n",
    "    global all_n_list\n",
    "    global F\n",
    "    global output_file\n",
    "    \n",
    "    node.equivalent_items = []\n",
    "    node.child_nodes = []\n",
    "    next_cad_items = []    \n",
    "    p1 = node.itemset\n",
    "    p1_n_list = get_n_list('-'.join(p1))\n",
    "    for item in cad_items:\n",
    "        p2 = [item] + p1[1:]\n",
    "        p = [item] + p1\n",
    "        p2_n_list = get_n_list('-'.join(p2))        \n",
    "        p_n_list = NL_interserction(p2_n_list, p1_n_list, support)\n",
    "        p_support = sum([item[1] for item in p_n_list])\n",
    "        p_key = '-'.join(p)\n",
    "        \n",
    "        if len(p_n_list) > 0: # add n_list for new k-itemset            \n",
    "            if p_key not in all_n_list:\n",
    "                all_n_list[p_key] = []\n",
    "            all_n_list[p_key] += p_n_list\n",
    "            \n",
    "        if p_support == node.support:\n",
    "            node.equivalent_items += [item]\n",
    "        elif p_support >= support:\n",
    "            node_ = FPTNode()\n",
    "            node_.label = item\n",
    "            node_.itemset = p\n",
    "            node_.support = p_support\n",
    "            node.child_nodes += [node_]\n",
    "            next_cad_items += [item]\n",
    "    \n",
    "    nd_fit = []        \n",
    "    if len(node.equivalent_items) > 0:\n",
    "        subsets = get_all_subsets(node.equivalent_items)\n",
    "        cand_itemsets = [('-'.join([item, node.label]), node.support) for item in subsets]\n",
    "        if len(parent_fit) == 0:\n",
    "            nd_fit = cand_itemsets\n",
    "        else:\n",
    "            nd_fit = []\n",
    "            for cand_item in cand_itemsets:\n",
    "                for parent_item in parent_fit:\n",
    "                    nd_fit.append(('-'.join([cand_item[0], parent_item[0]]), node.support))                    \n",
    "        \n",
    "        for x in nd_fit:\n",
    "            output_file.write(x[0] + \" #SUP: \" + str(x[1]) + \"\\n\")\n",
    "                        \n",
    "\n",
    "    if len(node.child_nodes) > 0:\n",
    "        for n in node.child_nodes:\n",
    "            aheads_ = [i for i in items_ordered[:items_ordered.index(n.label)] if i in next_cad_items]\n",
    "            if aheads_ == []:\n",
    "                output_file.write('-'.join(n.itemset) + \" #SUP: \" + str(n.support) + \"\\n\")\n",
    "            else:\n",
    "                building_pattern_tree(n, aheads_, nd_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepostplus():\n",
    "    global all_n_list\n",
    "    global output_file\n",
    "    \n",
    "    initial_time = time.time()\n",
    "    itemset_1 = make_itemset_1(input_file)\n",
    "    tree = build_ppc_tree(input_file, itemset_1)\n",
    "    \n",
    "    n_list = {}\n",
    "    make_n_list(tree, n_list)\n",
    "    \n",
    "    F = list(itemset_1.items())\n",
    "    F.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for x in F:\n",
    "        output_file.write(x[0] + \" #SUP: \" + str(x[1]) + \"\\n\")\n",
    "    items_ordered = [x[0] for x in F]\n",
    "    \n",
    "    n2_list = make_n2_list(n_list, items_ordered)\n",
    "    \n",
    "    all_n_list = copy.deepcopy(n2_list)\n",
    "    \n",
    "    for key, n_list in list(n2_list.items()):\n",
    "        item = key[:key.index('-')]\n",
    "        aheads = items_ordered[:items_ordered.index(item)]\n",
    "        node = FPTNode()\n",
    "        node.label = key\n",
    "        node.itemset = key.split('-')\n",
    "        node.support = sum([item[1] for item in n_list])\n",
    "        output_file.write(key + \" #SUP: \" + str(node.support) + \"\\n\")\n",
    "        building_pattern_tree(node, aheads, [])\n",
    "    final_time = time.time()\n",
    "    \n",
    "    #output_file.close()\n",
    "    print(\"Execution time (s):\", final_time - initial_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed: 4\n",
      "Execution time (s): 0.0009775161743164062\n",
      "removed: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5733186ac88f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmemory_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepostplus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[1;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                 \u001b[0mreturned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# finish timing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-bbe480d9a93e>\u001b[0m in \u001b[0;36mprepostplus\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" #SUP: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mitems_ordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "memory_usage((prepostplus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
